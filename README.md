# Hand Gesture Recognition PyTorch
В данной работе рассматривалась задача классификации динамических
жестов руки. Для решения использовались два типа архитектур нейронных
сетей:
* Рекуррентные сети (CNN+LSTM)
* Трехмерные сверточные сети (3D CNN)

![demo](3rdparty/wave_off_all_right.gif)

## Обучающее множество
Для тренировки был выбран австралийский датасет
[UAV-GESTURE](https://github.com/asankagp/UAV-GESTURE), 
предназначенный для управления дроном с помощью жестов рук.

## Требования 
* Python 3.6
* PyTorch (cuda 8.0)
* OpenCV
* PIL Image

## Использование
1. Скачать обучающее множество
    * Нарезать видеофайлы на кадры ```src/dataset_utils/uav_gesture/extract_frames_from_videos.py```
    * Поместить в каждую папку с кадрами файл, содержащий информацию о
    количестве кадров ```src/dataset_utils/uav_gesture/n_frames.py```
    * Выполнить разметку файлов на классы для тренировки и валидации ```src/dataset_utils/uav_gesture/split_data_to_train_and_valid.py```
    * Конвертировать разметку в JSON файл формата ActivityNet ```src/dataset_utils/uav_gesture/convert_dataset_to_json.py```
2. Обучение
    * Указать в параметрах ```opts.py``` следующие пути:
        * ```--video_path``` путь к папке с нарезанными видеофайлами
        * ```--annotation_directory``` путь к директории, содержащей файлы JSON с разметкой датасета
        * ```--annotation_path``` файл с разметкой, который будет выбран по умолчанию
        * ```--result_path``` директория, в которую будут сохранятся результаты обучения
    * Запустить файл ```main.py```
3. Тестирование
    * Указать в параметрах ```opts.py``` следующие пути:
        * ```--trained_model_path``` путь до обученной модели
        * ```--test_video_path``` путь к видеофайлу, на котором будет происходить тест модели.
        Если указано ```None```, то в качестве данных будет использоваться видеопоток с веб-камеры
    * Запустить файл ```test_application.py```

